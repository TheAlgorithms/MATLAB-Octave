{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import gzip\n",
    "TRAIN_DIR=\"C:\\\\Users\\\\super\\\\Desktop\\\\Eckovation\\\\SVM_Dataset\\\\train-mails\"\n",
    "TEST_DIR=\"C:\\\\Users\\\\super\\\\Desktop\\\\Eckovation\\\\SVM_Dataset\\\\test-mails\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load function for loading the model\n",
    "def load(file_name):\n",
    "    stream=gzip.open(file_name,\"rb\")\n",
    "    model=pickle.load(stream)\n",
    "    stream.close()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "def save(file_name,model):\n",
    "    stream=gzip.open(file_name,\"wb\")\n",
    "    pickle.dump(model,stream)\n",
    "    stream.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(root_dir):\n",
    "    all_words=[]\n",
    "    emails=[os.path.join(root_dir,f)for f in os.listdir(root_dir)]\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                words=line.split()\n",
    "                all_words+= words\n",
    "    dictionary=Counter(all_words)\n",
    "    list_to_remove=list(dictionary)\n",
    "    \n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha()==False:\n",
    "            del dictionary[item]\n",
    "        elif len(item)==1:\n",
    "            del dictionary[item]\n",
    "    dictionary=dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(mail_dir):\n",
    "    files=[os.path.join(mail_dir,fi)for fi in os.listdir(mail_dir)]\n",
    "    features_matrix=np.zeros((len(files),3000))\n",
    "    train_labels=np.zeros(len(files))\n",
    "    count=0;\n",
    "    docID=0;\n",
    "    \n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            for i,line in enumerate(fi):\n",
    "                if i==2:\n",
    "                    words=line.split()\n",
    "                    for word in words:\n",
    "                        wordID=0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0]==word:\n",
    "                                wordID=i\n",
    "                                features_matrix[docID,wordID]=words.count(word)\n",
    "        train_labels[docID]=0;\n",
    "        filepathtokens=fil.split('/')\n",
    "        lasttoken=filepathtokens[len(filepathtokens)-1]\n",
    "        if lasttoken.__contains__(\"spmsg\"):\n",
    "            train_labels[docID]=1;\n",
    "            count=count+1\n",
    "        docID=docID+1\n",
    "    return features_matrix,train_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Processing emails from file.\n"
     ]
    }
   ],
   "source": [
    "dictionary=make_dict(TRAIN_DIR)\n",
    "print(\"Reading and Processing emails from file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix,labels=extract_feature(TRAIN_DIR)\n",
    "test_feature_matrix,test_labels=extract_feature(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n"
     ]
    }
   ],
   "source": [
    "model=svm.SVC(kernel=\"rbf\",C=100,gamma=0.001)\n",
    "print(\"Training model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_matrix,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished classifying,Accuracy Score:\n",
      "0.9730769230769231\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=model.predict(test_feature_matrix)\n",
    "print(\"Finished classifying,Accuracy Score:\")\n",
    "print(accuracy_score(test_labels,predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
